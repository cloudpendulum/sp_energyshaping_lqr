{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "1e11ee3656404b88a4beb5e1eec76dd2",
    "deepnote_cell_height": 223.953125,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "# Tutorial: LQR and Region of Atraction for the Simple Pendulum\n",
    "\n",
    "In this tutorial, we will look at some optimal controllers for our simple pendulum. To do so, we will first linearize our system so that we can use a Linear-Quadratic Regulator. Then, we will use the PendulumPlant class to simulate it. We will also combine our LQR with a controller we have previously seen in order to provide a solution that stabilizes the system. Finally, we will test the controllers that we have developed on a real, remote, pendulum.\n",
    "\n",
    "**Pre-requisites**\n",
    "\n",
    "- Access to the Cloud Pendulum\n",
    "- Familiarity with infinite-horizon Linear-Quadratic Regulators.\n",
    "- Understanding of LaSalle's invariance principle and Lyapunov Analysis.\n",
    "\n",
    "**Goals**\n",
    "\n",
    "- Learning to implement controllers that guarantee stability under the correct conditions.\n",
    "- Understanding and using the Region of Attraction concept to stabilize our system.\n",
    "- Performing a swing-up with a real simple pendulum.\n",
    "\n",
    "This notebook is organized as follows:\n",
    "\n",
    "    1. Introduction\n",
    "        1.1. The simple pendulum\n",
    "        1.2. Energy Shaping\n",
    "    2. Linear-Quadratic Regulators\n",
    "        2.1. Linearization of the equations of motion\n",
    "        2.2. Infinite-horizon LQR\n",
    "    3. Region of Attraction\n",
    "        3.1. LaSalle's invariance principle\n",
    "        3.2. Energy Shaping + LQR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "fd1c36fbf0574164a9e2114370353d62",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_context_id": "6c7288b7-3123-4ac3-b25a-36877f0aa07c",
    "execution_millis": 2522,
    "execution_start": 1733233994236,
    "output_cleared": false,
    "source_hash": "b4147560"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy.linalg\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "from pendulum_plant import PendulumPlant, plot_timeseries\n",
    "from utils import direct_sphere\n",
    "from plot import plot_ellipse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "926ccafce6bf4c6fb031218681ef1dd0",
    "deepnote_cell_height": 108.390625,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## 1. Introduction\n",
    "### 1.1. The simple Pendulum\n",
    "\n",
    "<center><img src=\"media/pendulum_undamped_axes.png\" width=\"400\"></center>\n",
    "    \n",
    "Here, we can take a look again at how the *PendulumPlant* works...\n",
    "\n",
    "The cell below constructs a pendulum object with the specified dynamic parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "260159de1a1a46fdb514c0c7182e3e4c",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_context_id": "6c7288b7-3123-4ac3-b25a-36877f0aa07c",
    "execution_millis": 2,
    "execution_start": 1733234000103,
    "output_cleared": false,
    "source_hash": "a7bfa11b"
   },
   "outputs": [],
   "source": [
    "mass = 0.06                    # mass at the end of the pendulum [kg]\n",
    "length = 0.1                   # length of the rod [m]\n",
    "damping = 0.0004               # viscious friction [kg m/s]\n",
    "gravity = 9.81                 # gravity [kg m²/s]\n",
    "inertia = mass*length*length   # inertia of the pendulum [kg m²]\n",
    "torque_limit = np.inf          # torque limit of the motor, here we assume the motor can produce any torque\n",
    "\n",
    "pendulum = PendulumPlant(mass=mass,\n",
    "                         length=length,\n",
    "                         damping=damping,\n",
    "                         gravity=gravity,\n",
    "                         inertia=inertia,\n",
    "                         torque_limit=torque_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "c7eb7fd1f4874c349ed03ea61764a471",
    "deepnote_cell_height": 314.734375,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "In order to simulate and animate a motion of the pendulum you can call the simulate_and_animate class method. The arguments are:\n",
    "\n",
    "    - t0: the initial time\n",
    "    - y0: the initial state\n",
    "    - tf: the final time\n",
    "    - dt: the integration timestep\n",
    "    - controller: controller object providing torques for the motor (introduced later)\n",
    "    - integrator: the integration method. we will be using \"runge_kutta\"\n",
    "    \n",
    "The method returns the trajectory split in to time (T), state (X) and torques (U) as well as an animation object.\n",
    "\n",
    "**Note:** If you do not need the animation you can also call the method *simulate* with the same parameters. The method returns T, X, U but no animation object. Making an animation **takes some time**.\n",
    "\n",
    "In the next cell, we simulate the damped pendulum for 10 seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "6e47bb1533d74622b47e6f2b415f1219",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_context_id": "6c7288b7-3123-4ac3-b25a-36877f0aa07c",
    "execution_millis": 457,
    "execution_start": 1733234002821,
    "output_cleared": false,
    "source_hash": "ef182379"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "T, X, U, anim = pendulum.simulate_and_animate(\n",
    "              t0=0.0,\n",
    "              y0=[2.0, 0.0],\n",
    "              tf=10.0,\n",
    "              dt=0.01,\n",
    "              controller=None,\n",
    "              integrator=\"runge_kutta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the plot_timeseries function to plot the trajectories (position, velocity and torque). Of course you can also plot these in any other way you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timeseries(T, X, U)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "03dc8618d35b496e89c7f90560d514fd",
    "deepnote_cell_height": 52.390625,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "For testing/debugging it might be better to simply simulate without animation and then see the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b2549df99b9040f38572a7c884e0db6f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_context_id": "6c7288b7-3123-4ac3-b25a-36877f0aa07c",
    "execution_millis": 91831,
    "execution_start": 1733234008145,
    "output_cleared": false,
    "scrolled": true,
    "source_hash": "429ba5ca"
   },
   "outputs": [],
   "source": [
    "Tsim_ff, Xsim_ff, Usim_ff = pendulum.simulate(\n",
    "              t0=0.0,\n",
    "              y0=[1.57, 0.0],\n",
    "              tf=10.0,\n",
    "              dt=0.01,\n",
    "              controller=None,\n",
    "              integrator=\"runge_kutta\")\n",
    "plot_timeseries(Tsim_ff, Xsim_ff, Usim_ff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Energy Shaping\n",
    "\n",
    "The Energy Shaping controller uses the total energy in the system to make it easier to reach a state which is energetically very far from our current one while respecting the limit on torque that can be provided. It works in the following way:\n",
    "\n",
    "- First, we calculate the current total mechanical energy of our system. It is given by the following expression:\n",
    "\n",
    "$$\n",
    "E_{total} = E_{potential} + E_{kinetic}\n",
    "$$\n",
    "$$\n",
    "E_{potential} = m g l (1 -\\cos(\\theta))\n",
    "$$\n",
    "$$\n",
    "E_{kinetic} = \\frac{1}{2} I \\dot{\\theta}^2\n",
    "$$\n",
    "\n",
    "- Then, we calculate the total energy associated with our goal state, $E_{goal}$\n",
    "- Lastly, we define a simple control law that increases the energy of the system if it is below that of the goal state or decreases it otherwise.\n",
    "\n",
    "$$\n",
    "u = -K (E_{goal} - E_{total})\n",
    "$$\n",
    "\n",
    "where $u$ is the torque provided by the motor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4c8cdf7c8433483f868e1a0d036c5c5b",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_context_id": "6c7288b7-3123-4ac3-b25a-36877f0aa07c",
    "execution_millis": 3,
    "execution_start": 1733234630820,
    "output_cleared": false,
    "source_hash": "c7fb1a1d"
   },
   "outputs": [],
   "source": [
    "class EnergyShapingController():\n",
    "    def __init__(self, mass, length, damping, torque_limit, gravity, K):\n",
    "        self.K = K\n",
    "        self.m = mass\n",
    "        self.l = length\n",
    "        self.g = gravity\n",
    "        self.b = damping\n",
    "        self.torque_limit = torque_limit\n",
    "\n",
    "    def get_control_output(self, x):\n",
    "        # Create a Energy Shaping Controller for swing up of simple pendulum \n",
    "        Ted = self.m * self.l * self.g  # desired energy\n",
    "        Tec = (self.m * (self.l * x[1])**2)/2 - self.m * self.l * self.g * np.cos(x[0]) # current energy\n",
    "        tau_es = -self.K * x[1] * (Tec - Ted) + self.b*x[1]\n",
    "        tau = np.clip(tau_es,-self.torque_limit, self.torque_limit)\n",
    "        \n",
    "        return tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ec922ccd2c6f4238a4dd60390d1d810f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_context_id": "6c7288b7-3123-4ac3-b25a-36877f0aa07c",
    "execution_millis": 4,
    "execution_start": 1733234637537,
    "output_cleared": false,
    "source_hash": "bbdc39d5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "energy_shaping_controller = EnergyShapingController(mass=mass, length=length, damping = damping, torque_limit=0.03, gravity=gravity, K=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "488462a7b73944499dfbb65f1255d943",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_context_id": "6c7288b7-3123-4ac3-b25a-36877f0aa07c",
    "execution_millis": 436,
    "execution_start": 1733234642497,
    "output_cleared": false,
    "owner_user_id": "2177249d-3045-48b4-86d2-efc46aa603b3",
    "source_hash": "5d8fdd97",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "T, X, U, anim = pendulum.simulate_and_animate(\n",
    "              t0=0.0,\n",
    "              y0=[0.001, 0.0],\n",
    "              tf=10.0,\n",
    "              dt=0.01,\n",
    "              controller=energy_shaping_controller,\n",
    "              integrator=\"runge_kutta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that running the following cell may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "5d1ba0c0c7294db3a6e8066e351dfca0",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_context_id": "6c7288b7-3123-4ac3-b25a-36877f0aa07c",
    "execution_millis": 89918,
    "execution_start": 1733234647252,
    "output_cleared": false,
    "scrolled": true,
    "source_hash": "429ba5ca",
    "tags": []
   },
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4a072579ea644e0bb217aa98b7f249e7",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 245,
    "execution_start": 1719564873867,
    "output_cleared": false,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_timeseries(T, X, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tsim_es, Xsim_es, Usim_es = pendulum.simulate(\n",
    "              t0=0.0,\n",
    "              y0=[0.001, 0.0],\n",
    "              tf=10.0,\n",
    "              dt=0.01,\n",
    "              controller=energy_shaping_controller,\n",
    "              integrator=\"runge_kutta\")\n",
    "plot_timeseries(Tsim_es, Xsim_es, Usim_es)\n",
    "\n",
    "\n",
    "# Export the data to csv file\n",
    "simulation_csv_data_es = np.array([Tsim_es, np.asarray(Xsim_es).T[0], np.asarray(Xsim_es).T[1],Usim_es]).T\n",
    "np.savetxt(\"es_simulation_data_es.csv\", simulation_csv_data_es, delimiter=',', header=\"time,pos,vel,tau\", comments=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "42fd2ad9c6d34dbbb3540ea77606ac1d",
    "deepnote_cell_height": 254.34375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## 2. Linear-Quadratic Regulators\n",
    "\n",
    "We will use a LQR to hold the \"up\" position. That way, when we reach the top, we can remain in that position.\n",
    "\n",
    "### 2.1 Linearization of the equations of motion\n",
    "\n",
    "To be able to use a LQR, we must first write the equations governing our system in a way that fits the following expression:\n",
    "\n",
    "$$\n",
    "\\dot{x} = Ax + Bu\n",
    "$$\n",
    "\n",
    "For the simple pendulum, this is the system dynamics, which currently have the shape:\n",
    "\n",
    "$$\n",
    "I \\ddot{\\theta} = \\tau - m g l \\sin(\\theta) - b \\dot{\\theta}\n",
    "$$\n",
    "\n",
    "where $I = m l^2$\n",
    "\n",
    "Consider our state vector $x$ to be $\\left[ \\begin{matrix} \\theta - \\theta^* & \\dot{\\theta} - \\dot{\\theta}^* \\end{matrix} \\right]^T$. We can use Taylor series to linearize the dynamics around a point. To linearize a function around a point $x^*$ with a Taylor expansion, the following equation is applied:\n",
    "\n",
    "$$\n",
    "f(x) \\approx \\sum_{n=0}^{\\infty} f^{(n)}(x^*)\\frac{(x-x^*)^n}{n!}\n",
    "$$\n",
    "\n",
    "### Think-Pair-Share (10 min)\n",
    "\n",
    "- Using a first order Taylor series, linearize the dynamics around $\\theta^* = \\pi$, $\\dot{\\theta}^* = 0$.\n",
    "- Rewrite the linearized equations of motion into the shape $\\dot{x} = Ax+Bu$.\n",
    "- Implement the linearized dynamics in the *LQRController* class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "1801ec1f2ba447ab995686e4f2d42609",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 65,
    "execution_start": 1719565752003,
    "output_cleared": false,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LQRController():\n",
    "    def __init__(self, mass, length, gravity, damping, torque_limit, Q, R):\n",
    "        self.Q = Q                 # 2x2 Matrix cost on state error\n",
    "        self.R = R                 # 1x1 Matrix cost on actuation\n",
    "        self.m = mass\n",
    "        self.l = length\n",
    "        self.g = gravity\n",
    "        self.b = damping\n",
    "        self.torque_limit = torque_limit\n",
    "        A, B = self.linearize()\n",
    "        self.K = np.zeros((2, 2))\n",
    "        # Continuous Time LQR\n",
    "        self.K, self.S, _ = lqr(A, B, Q, R)\n",
    "        print(\"LQR Gain Matrix (K):\", self.K)\n",
    "        # Discrete Time LQR\n",
    "        # self.K, _, _ = dlqr(A, B, Q, R)\n",
    "    \n",
    "    def linearize(self):\n",
    "        # Linearized equations of motion for simple pendulum\n",
    "        # at the upright/topmost state (pi, 0)\n",
    "        # Either Continuous form: x_dot = Ax + Bu\n",
    "        # Or discrete form: x[n+1] = Ax[n] + Bu[n]\n",
    "\n",
    "        ### \n",
    "        A = np.array([[0, 0], [0, 0]]) # Type here\n",
    "        B = np.array([[0],[0]]) # Type here\n",
    "        ###\n",
    "        \n",
    "        return A, B\n",
    "\n",
    "    def get_control_output(self, x):\n",
    "        # Use the LQR Gain matrix K to create the controller.\n",
    "        tau = 0 # Type here\n",
    "        # Add a torque limit before returning the tau value.\n",
    "        return np.clip(tau[0], -self.torque_limit, self.torque_limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Infinite-horizon LQR\n",
    "\n",
    "For our optimal infinite-horizon LQR controller, we need to define a cost function. A simple, convex, cost function is the following:\n",
    "\n",
    "$$\n",
    "J = \\int_0^\\infty \\left[ \\mathbf{x}^T \\mathbf{Q} \\mathbf{x} + \\mathbf{u}^T \\mathbf{R} \\mathbf{u} \\right] dt,\n",
    "    \\quad \\mathbf{Q} = \\mathbf{Q}^T \\succeq \\mathbf{0}, \\mathbf{R} = \\mathbf{R}^T \\succ 0.\n",
    "$$\n",
    "\n",
    "Our goal with this controller is to find the cost-to-go function that solves the following Hamilton-Jacobi-Bellman equation:\n",
    "\n",
    "$$\n",
    "\\forall \\mathbf{x}, \\quad 0 = \\min_{\\mathbf{u}} \\left[ \\mathbf{x}^T \\mathbf{Q}\n",
    "    \\mathbf{x} + \\mathbf{u}^T \\mathbf{R} \\mathbf{u} + \\frac{\\partial J^*}{\\partial \\mathbf{x}} \\left( \\mathbf{A} \\mathbf{x} + \\mathbf{B} \\mathbf{u} \\right)\n",
    "    \\right].\n",
    "$$\n",
    "\n",
    "Where $J^*(\\mathbf{x})$ is the function that provides the cost that we will incurr to get from point $\\mathbf{x}$ to the goal. For this problem, our cost-to-go function will have the following shape:\n",
    "\n",
    "$$\n",
    "J^*(\\mathbf{x}) = \\mathbf{x}^T \\mathbf{S} \\mathbf{x}, \\quad \\mathbf{S} = \\mathbf{S}^T \\succeq 0\n",
    "$$\n",
    "\n",
    "The gradient of the cost-to-go function then is:\n",
    "\n",
    "$$ \\frac{\\partial J^*}{\\partial \\mathbf{x}} = 2 \\mathbf{x}^T \\mathbf{S}$$\n",
    "\n",
    "With this information we can then derive the control law that will produce the optimal control policy:\n",
    "\n",
    "$$\n",
    "\\mathbf{u}^* = -\\mathbf{R}^{-1} \\mathbf{B}^T \\mathbf{S} \\mathbf{x} = -\\mathbf{K} \\mathbf{x}\n",
    "$$\n",
    "\n",
    "After substituting $\\mathbf{u}$ in the HJB equation with the optimal control policy, we get the following equation:\n",
    "\n",
    "$$\n",
    "0 = \\mathbf{S} \\mathbf{A} + \\mathbf{A}^T \\mathbf{S} - \\mathbf{S} \\mathbf{B} \\mathbf{R}^{-1} \\mathbf{B}^T \\mathbf{S} + \\mathbf{Q}\n",
    "$$\n",
    "\n",
    "This is the continuous Riccati equation, which can be solved using scipy's *solve_continuous_are*. This is implemented in the *lqr* function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lqr(A,B,Q,R):\n",
    "    \"\"\"Solve the continuous time lqr controller.\n",
    "    dx/dt = A x + B u\n",
    "    cost = integral x.T*Q*x + u.T*R*u\n",
    "    \"\"\"\n",
    "    #ref Bertsekas, p.151\n",
    "\n",
    "    #Solve the Algebraic Riccati Equation\n",
    "    S = scipy.linalg.solve_continuous_are(A, B, Q, R)\n",
    "\n",
    "    #compute the LQR gain\n",
    "    K = scipy.linalg.inv(R).dot(B.T.dot(S))\n",
    "    eigVals, eigVecs = scipy.linalg.eig(A-B.dot(K))\n",
    "    return K, S, eigVals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can define the weights of the cost function and instantiate the LQR controller.\n",
    "\n",
    "### Think-Pair-Share (5 min)\n",
    "- Tune the LQR controller by modifying the penalties associated to the position and velocity error. $\\mathbf{Q}$ and $\\mathbf{R}$ should take the shapes:\n",
    "\n",
    "$$\n",
    "\\mathbf{Q} = \\left[ \\begin{matrix} w_{\\theta} & 0 \\\\ 0 & w_{\\dot{\\theta}} \\end{matrix} \\right], \\; \\mathbf{R} = \\left[ \\begin{matrix} w_{u} \\end{matrix} \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array([[0, 0], [0, 0]]) # Type here\n",
    "R = np.array([[0]]) # Type here\n",
    "lqr_controller = LQRController(mass=mass, length=length, gravity=gravity, damping=damping, torque_limit=0.03, Q=Q, R=R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulating the pendulum starting from a state close to the goal, we should see that the controller indeed stabilizes the pendulum in the up position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "f8cf39a79cbc471dad3b95c426bdbb98",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 400,
    "execution_start": 1719565777344,
    "output_cleared": false,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "T, X, U, anim = pendulum.simulate_and_animate(\n",
    "              t0=0.0,\n",
    "              y0=[np.pi-0.2, -0.1],\n",
    "              tf=10.0,\n",
    "              dt=0.01,\n",
    "              controller=lqr_controller,\n",
    "              integrator=\"runge_kutta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "ebcfcdb5dd2d4b66a03b2261d9679e2d",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 104004,
    "execution_start": 1719565780927,
    "output_cleared": false,
    "scrolled": true,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "659800cb12e446c9a7f2fda4380f1b25",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 247,
    "execution_start": 1719565914671,
    "output_cleared": false,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_timeseries(T, X, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tsim_lqr, Xsim_lqr, Usim_lqr = pendulum.simulate(\n",
    "              t0=0.0,\n",
    "              y0=[np.pi-0.2, -0.1],\n",
    "              tf=10.0,\n",
    "              dt=0.01,\n",
    "              controller=lqr_controller,\n",
    "              integrator=\"runge_kutta\")\n",
    "plot_timeseries(Tsim_lqr, Xsim_lqr, Usim_lqr)\n",
    "\n",
    "# Measured Position\n",
    "plt.figure\n",
    "plt.plot(Tsim_lqr, np.asarray(Xsim_lqr).T[0])\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Position (rad)\")\n",
    "plt.title(\"Position (rad) vs Time (s)\")\n",
    "plt.show()\n",
    "# Measured Velocity\n",
    "plt.figure\n",
    "plt.plot(Tsim_lqr, np.asarray(Xsim_lqr).T[1])\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Velocity (rad/s)\")\n",
    "plt.title(\"Velocity (rad/s) vs Time (s)\")\n",
    "plt.show()\n",
    "# Measured Torque\n",
    "plt.figure\n",
    "plt.plot(Tsim_lqr, Usim_lqr)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Torque (Nm)\")\n",
    "plt.title(\"Torque (Nm) vs Time (s)\")\n",
    "plt.show()\n",
    "\n",
    "# Export the data to csv file\n",
    "simulation_csv_data_lqr = np.array([Tsim_lqr, np.asarray(Xsim_lqr).T[0], np.asarray(Xsim_lqr).T[1],Usim_lqr]).T\n",
    "np.savetxt(\"es_simulation_data_lqr.csv\", simulation_csv_data_lqr, delimiter=',', header=\"time,pos,vel,tau\", comments=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Region of Attraction\n",
    "\n",
    "We can repeat this test for a set of randomly chosen starting points in the vicinity of the goal state and show that the controller will stabilize the system around the goal state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "4a33d9387ba845c6816761186e7a591a",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1725,
    "execution_start": 1719566075344,
    "output_cleared": false,
    "scrolled": true,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_LQR = []\n",
    "for i in range(10):\n",
    "    # Your Code here\n",
    "    # Generate random states here in the neighbourhood of (pi, 0)\n",
    "    #y0_random = [random.uniform(np.pi-0.001,np.pi+0.001), random.uniform(-0.005,0.005)]\n",
    "    y0_random = [random.uniform(np.pi-0.2,np.pi+0.2), random.uniform(-0.8,0.8)]\n",
    "    #y0_random = [random.uniform(np.pi-0.5,np.pi+0.5), random.uniform(-0.5,0.5)]\n",
    "    T, X, U = pendulum.simulate(\n",
    "                t0=0.0,\n",
    "                y0=y0_random,\n",
    "                tf=10.0,\n",
    "                dt=0.01,\n",
    "                controller=lqr_controller,\n",
    "                integrator=\"runge_kutta\")\n",
    "    X_LQR.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "86a1abbc9ca14cb9abc970b6e0a240b2",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 282,
    "execution_start": 1719566080544,
    "output_cleared": false,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot Positions\n",
    "for i in range(10):\n",
    "    plt.plot(T, np.asarray(X_LQR[i]).T[0], label=str(i))\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "d4b647ebbb004f61b83629f0e009e35f",
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 294,
    "execution_start": 1719566121535,
    "output_cleared": false,
    "scrolled": true,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot Velocities\n",
    "for i in range(10):\n",
    "    plt.plot(T, np.asarray(X_LQR[i]).T[1], label=str(i))\n",
    "\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Think-Pair-Share (5 min)\n",
    "\n",
    "- If the system didn't reach the goal from all the starting points in the previous cells, tune it further so it will.\n",
    "- Tune the controller so that it can reach the top from a far less convenient position like the one in the simulation from the following cells. Does it reach the top? Why (or why not)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. LaSalle's invariance principle\n",
    "\n",
    "LaSalle's invariance principle states that if, for a system with continuous dynamics defined by $\\dot{x} = f(x)$, we can produce a scalar function $V(x)$ with continuous derivatives for which we have:\n",
    "\n",
    "- $V(\\mathbf{x})>0 \\;\\;\\; \\forall \\mathbf{x} \\in \\mathcal{G}, \\mathbf{x} \\neq \\mathbf{0}$ and $V(\\mathbf{0}) = 0$\n",
    "- $\\dot{V}(\\mathbf{x}) \\leq 0 \\;\\;\\; \\forall \\mathbf{x} \\in \\mathcal{G}$\n",
    "\n",
    "then, the origin is locally asymptotically stable and set $\\mathcal{G}$ is contained within its region of attraction.\n",
    "\n",
    "We can exploit this information to narrow down a set which is entirely within the region of attraction of the origin $x = \\left[ \\begin{matrix} \\pi & 0\\end{matrix} \\right]^T$. A simple way of doing so is to pick a shape for set $\\mathcal{G}$ and scale it so that it is within the region of attraction. \n",
    "\n",
    "We will use an ellipse centered on the origin and defined by:\n",
    "\n",
    "$$\n",
    "V(\\mathbf{x}) \\leq \\rho\n",
    "$$\n",
    "\n",
    "Remember that the cost-to-go can be selected as a candidate Lyapunov function i.e., $V(\\mathbf{x}) = \\mathbf{x}^T S \\mathbf{x}$\n",
    "\n",
    "To find the value of $\\rho$ that provides the largest region of attraction guaranteeing stability, we can follow the procedure:\n",
    "\n",
    "- Set an initial value of $\\rho$ which we know is unrealistically large.\n",
    "- Start sampling points from inside the ellipse. If at that point the conditions outlined in LaSalle's invariance principle hold, that point is part of the region of attraction. If LaSalle's principle of invariance does not hold for that point, we reduce the size of the ellipse until the point is no longer in it.\n",
    "- We repeat the previous step until we converge to the largest ellipse which only contains points in the region of attraction.\n",
    "\n",
    "Complete the following cells so that this strategy is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_ellipsoid(M,rho,r_i=0,r_o=1):\n",
    "    \"\"\"sample directly from the ellipsoid defined by xT M x.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    M : np.array\n",
    "        Matrix M such that xT M x leq rho defines the hyperellipsoid to sample from\n",
    "    rho : float\n",
    "        rho such that xT M x leq rho defines the hyperellipsoid to sample from\n",
    "    r_i : int, optional\n",
    "        inner radius, by default 0\n",
    "    r_o : int, optional\n",
    "        outer radius, by default 1\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        random vector from within the hyperellipsoid\n",
    "    \"\"\"\n",
    "    lamb,eigV=np.linalg.eigh(M/rho) \n",
    "    d=len(M)\n",
    "    xy=direct_sphere(d,r_i=r_i,r_o=r_o) #sample from outer shells\n",
    "    T=np.linalg.inv(np.dot(np.diag(np.sqrt(lamb)),eigV.T)) #transform sphere to ellipsoid (refer to e.g. boyd lectures on linear algebra)\n",
    "    return np.dot(T,xy.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def najafi_based_sampling(\n",
    "    plant, controller, n=10000, rho0=100, M=None, x_star=np.array([np.pi, 0])\n",
    "):\n",
    "    \"\"\"Estimate the RoA for the closed loop dynamics using the method introduced in Najafi, E., Babuška, R. & Lopes, G.A.D. A fast sampling method for estimating the domain of attraction. Nonlinear Dyn 86, 823–834 (2016). https://doi.org/10.1007/s11071-016-2926-7\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    plant : simple_pendulum.model.pendulum_plant\n",
    "        configured pendulum plant object\n",
    "    controller : simple_pendulum.controllers.lqr.lqr_controller\n",
    "        configured lqr controller object\n",
    "    n : int, optional\n",
    "        number of samples, by default 100000\n",
    "    rho0 : int, optional\n",
    "        initial estimate of rho, by default 10\n",
    "    M : np.array, optional\n",
    "        M, such that x_barT M x_bar is the Lyapunov fct. by default None, and controller.S is used\n",
    "    x_star : np.array, optional\n",
    "        nominal position (fixed point of the nonlinear dynamics)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rho : float\n",
    "        estimated value of rho\n",
    "    M : np.array\n",
    "        M\n",
    "    points: list containing all the points that were tested\n",
    "    \"\"\"\n",
    "\n",
    "    rho = rho0\n",
    "\n",
    "    points = []\n",
    "    \n",
    "    if M is None:\n",
    "        M = np.array(controller.S)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    for i in range(n):\n",
    "        # sample initial state from sublevel set\n",
    "        # check if it fullfills Lyapunov conditions\n",
    "        x_bar = sample_from_ellipsoid(M, rho)\n",
    "        x = x_star + x_bar\n",
    "\n",
    "        tau = controller.get_control_output([x[0], x[1]])\n",
    "\n",
    "        xdot = plant.rhs(0, x, tau)\n",
    "\n",
    "        V = 0 # Type here your candidate Lyapunov function, you may use @ in python for matmult\n",
    "\n",
    "        Vdot = 2 * np.dot(x_bar, np.dot(M, xdot))\n",
    "\n",
    "        if V > rho:\n",
    "            print(\"something is fishy\")\n",
    "        # V < rho is true trivially, because we sample from the ellipsoid\n",
    "        if Vdot > 0.0:  # if one of the lyapunov conditions is not satisfied\n",
    "            rho = V\n",
    "\n",
    "        points.append(x)\n",
    "    \n",
    "    return rho, M, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rho, M, points = najafi_based_sampling(pendulum, lqr_controller, n=1000)\n",
    "print(\"rho: \", rho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to plot the ellipse of the region of attraction and the points which have been sampled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ellipse(np.pi, 0, rho, M, points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Energy Shaping + LQR\n",
    "\n",
    "We can now combine Energy Shaping and LQR to produce a controller which can achieve the swing-up with the underactuated simple pendulum and stabilize at the top.\n",
    "\n",
    "### Think-Pair-Share \n",
    "\n",
    "The class defined in the following cell is a controller which combines an energy shaping controller with a LQR to stabilize itself once it has reached the top. Use $\\mathcal{G}$ and/or $\\rho$ to determine when the controller should be switched from Energy Shaping to LQR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "7165ca04674b44389f0662b8b76d51ef",
    "deepnote_app_is_code_hidden": true,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 128,
    "execution_start": 1719531331186,
    "is_code_hidden": true,
    "output_cleared": false,
    "source_hash": null,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EnergyShapingAndLQRController():\n",
    "    \"\"\"\n",
    "    Controller which swings up the pendulum with the energy shaping\n",
    "    controller and stabilizes the pendulum with the lqr controller.\n",
    "    \"\"\"\n",
    "    def __init__(self, mass=1.0, length=0.5, damping=0.1,\n",
    "                 gravity=9.81, torque_limit=np.inf, K=1.0,\n",
    "                 Q=np.diag((10, 1)), R=np.array([[1]]), compute_RoA=False):\n",
    "        self.m = mass\n",
    "        self.l = length\n",
    "        self.b = damping\n",
    "        self.g = gravity\n",
    "\n",
    "        self.energy_shaping_controller = EnergyShapingController(mass=mass,\n",
    "                                                                 length=length,\n",
    "                                                                 damping=damping,\n",
    "                                                                 gravity=gravity,\n",
    "                                                                 torque_limit=torque_limit,\n",
    "                                                                 K=K)\n",
    "        self.lqr_controller = LQRController(mass=mass,\n",
    "                                            length=length,\n",
    "                                            damping=damping,\n",
    "                                            gravity=gravity,\n",
    "                                            torque_limit=torque_limit,\n",
    "                                            Q=Q,\n",
    "                                            R=R)\n",
    "\n",
    "        self.active_controller = \"none\"\n",
    "        self.swingup_time = None\n",
    "        \n",
    "        self.meas_time = 0.0\n",
    "\n",
    "    def set_RoA(self, M, rho):\n",
    "        self.M = M\n",
    "        self.rho = rho\n",
    "\n",
    "    def is_in_RoA(self, x):\n",
    "\n",
    "        x = np.array(x)\n",
    "\n",
    "        if (x.T @ self.M @ x) < self.rho:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def get_control_output(self, x):\n",
    "        # Measured State\n",
    "        meas_pos = x[0] \n",
    "        meas_vel = x[1]\n",
    "        # Desired Goal State\n",
    "        des_pos = np.pi \n",
    "        des_vel = 0.0\n",
    "        \n",
    "        #u = self.lqr_controller.get_control_output(x)\n",
    "        u = self.energy_shaping_controller.get_control_output(x)\n",
    "        th = meas_pos + np.pi\n",
    "        th = (th + np.pi) % (2*np.pi) - np.pi\n",
    "        \n",
    "        #if (np.abs(th) < self.eps[0] and\n",
    "        #    np.abs(meas_vel) < self.eps[1]):\n",
    "        \n",
    "        if self.is_in_RoA([th, meas_vel]):\n",
    "            #self.swingup_time = self.meas_time\n",
    "            #print(\"Inside ROA!\")\n",
    "            #print(\"th:\", th, \"th_dot: \", meas_vel)\n",
    "            if u is not None:\n",
    "                if self.active_controller != \"lqr\":\n",
    "                    self.active_controller = \"lqr\"\n",
    "                    print(\"Switching to lqr\")\n",
    "                u = self.lqr_controller.get_control_output(x)\n",
    "                #print(\"lqr: \", u)\n",
    "                #print(\"u: \",u)\n",
    "            else:\n",
    "                if self.active_controller != \"EnergyShaping\":\n",
    "                    self.active_controller = \"EnergyShaping\"\n",
    "                    print(\"Switching to EnergyShaping\")\n",
    "                u = self.energy_shaping_controller.get_control_output(x)\n",
    "                #print(\"ES: \", u)\n",
    "        #else:\n",
    "            #print(\"outside RoA\")\n",
    "        return u\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "b1a49a6cc38b414fb341c8f49f35bf57",
    "deepnote_app_is_code_hidden": true,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 55,
    "execution_start": 1719531335769,
    "is_code_hidden": true,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "Q = np.array([[0.001, 0], [0, 0.0001]])\n",
    "R = np.array([[1]])\n",
    "K = 0.1\n",
    "es_lqr_controller = EnergyShapingAndLQRController(mass=mass, length=length, damping=damping, gravity=gravity, torque_limit=0.03, K=K, Q=Q, R=R)\n",
    "rho, M = najafi_based_sampling(pendulum, lqr_controller, n=1000)[0:2]\n",
    "es_lqr_controller.set_RoA(M, rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "73bdf2030cd0474abedec7fbaf6d5816",
    "deepnote_app_is_code_hidden": true,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 330,
    "execution_start": 1719531338371,
    "is_code_hidden": true,
    "source_hash": null
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "T, X, U, anim = pendulum.simulate_and_animate(\n",
    "              t0=0.0,\n",
    "              y0=[0.001, 0.0],\n",
    "              tf=10.0,\n",
    "              dt=0.01,\n",
    "              controller=es_lqr_controller,\n",
    "              integrator=\"runge_kutta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "52c6aa44207c45fdb4344f1ead8e03e7",
    "deepnote_cell_type": "code",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_timeseries(T, X, U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tsim_es_lqr, Xsim_es_lqr, Usim_es_lqr = pendulum.simulate(\n",
    "              t0=0.0,\n",
    "              y0=[0.001, 0.0],\n",
    "              tf=5.0,\n",
    "              dt=0.01,\n",
    "              controller=es_lqr_controller,\n",
    "              integrator=\"runge_kutta\")\n",
    "plot_timeseries(Tsim_es_lqr, Xsim_es_lqr, Usim_es_lqr)\n",
    "\n",
    "# Measured Position\n",
    "plt.figure\n",
    "plt.plot(Tsim_es_lqr, np.asarray(Xsim_es_lqr).T[0])\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Position (rad)\")\n",
    "plt.title(\"Position (rad) vs Time (s)\")\n",
    "plt.show()\n",
    "# Measured Velocity\n",
    "plt.figure\n",
    "plt.plot(Tsim_es_lqr, np.asarray(Xsim_es_lqr).T[1])\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Velocity (rad/s)\")\n",
    "plt.title(\"Velocity (rad/s) vs Time (s)\")\n",
    "plt.show()\n",
    "# Measured Torque\n",
    "plt.figure\n",
    "plt.plot(Tsim_es_lqr, Usim_es_lqr)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Torque (Nm)\")\n",
    "plt.title(\"Torque (Nm) vs Time (s)\")\n",
    "plt.show()\n",
    "\n",
    "# Export the data to csv file\n",
    "simulation_csv_data_es_lqr = np.array([Tsim_es_lqr, np.asarray(Xsim_es_lqr).T[0], np.asarray(Xsim_es_lqr).T[1],Usim_es_lqr]).T\n",
    "np.savetxt(\"es_simulation_data_es_lqr.csv\", simulation_csv_data_es_lqr, delimiter=',', header=\"time,pos,vel,tau\", comments=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hardware Experiments with the Cloud Pendulum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following image shows a hardware prototype of an active pendulum system actuated with a small direct drive actuator (GL35 from T-motors). The control electronics are provided by MAB robotics. This system has been integrated in Chalmers Cloud Pendulum infrastructure and you can remotely access the pendulum and get live experimental data from it with the comfort of your web-browsers. You get to be alpha testers of the system!\n",
    "\n",
    "<div style=\"display: flex; justify-content: space-around;\">\n",
    "    <div><img src=\"media/pendulum_hardware.jpeg\" width=\"400\"></div>\n",
    "    <div><img src=\"media/cp_fast.gif\" width=\"450\"></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_token = \"Your User Token Here\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4a. Energy Shaping Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = 5 # Final time (s)\n",
    "dt = 0.01 # Time step (s)\n",
    "Treal_es, Xreal_es, Ureal_es, Ureal_es_des, video_path = pendulum.run_on_hardware(tf, dt, controller=energy_shaping_controller, user_token=user_token, preparation_time = 5.0) \n",
    "\n",
    "# Measured Position\n",
    "plt.figure\n",
    "plt.plot(Treal_es, np.asarray(Xreal_es).T[0])\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Position (rad)\")\n",
    "plt.title(\"Position (rad) vs Time (s)\")\n",
    "plt.show()\n",
    "\n",
    "# Measured Velocity\n",
    "plt.figure\n",
    "plt.plot(Treal_es, np.asarray(Xreal_es).T[1])\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Velocity (rad/s)\")\n",
    "plt.title(\"Velocity (rad/s) vs Time (s)\")\n",
    "plt.show()\n",
    "\n",
    "# Measured Torque\n",
    "plt.figure\n",
    "plt.plot(Treal_es, Ureal_es)\n",
    "plt.plot(Treal_es, Ureal_es_des)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Torque (Nm)\")\n",
    "plt.title(\"Torque (Nm) vs Time (s)\")\n",
    "plt.show()\n",
    "\n",
    "# Export the data to csv file\n",
    "measured_csv_data_es = np.array([Treal_es, np.asarray(Xreal_es).T[0], np.asarray(Xreal_es).T[1],Ureal_es]).T\n",
    "np.savetxt(\"es_measured_data_es.csv\", measured_csv_data_es, delimiter=',', header=\"time,pos,vel,tau\", comments=\"\")\n",
    "\n",
    "# Show the video\n",
    "from IPython.display import Video\n",
    "Video(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b. LQR Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = 10 # Final time (s)\n",
    "dt = 0.01 # Time step (s)\n",
    "x0 = [2.7, 0.0] # Desired initial state. Note: desired velocity won't be respected in present implementation.\n",
    "Treal_lqr, Xreal_lqr, Ureal_lqr, Ureal_lqr_des, video_path = pendulum.run_on_hardware(tf, dt, controller=lqr_controller, user_token=user_token, x0=x0, preparation_time = 5.0) \n",
    "\n",
    "# Measured Position\n",
    "plt.figure\n",
    "plt.plot(Treal_lqr, np.asarray(Xreal_lqr).T[0])\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Position (rad)\")\n",
    "plt.title(\"Position (rad) vs Time (s)\")\n",
    "plt.show()\n",
    "\n",
    "# Measured Velocity\n",
    "plt.figure\n",
    "plt.plot(Treal_lqr, np.asarray(Xreal_lqr).T[1])\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Velocity (rad/s)\")\n",
    "plt.title(\"Velocity (rad/s) vs Time (s)\")\n",
    "plt.show()\n",
    "\n",
    "# Measured Torque\n",
    "plt.figure\n",
    "plt.plot(Treal_lqr, Ureal_lqr)\n",
    "plt.plot(Treal_lqr, Ureal_lqr_des)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Torque (Nm)\")\n",
    "plt.title(\"Torque (Nm) vs Time (s)\")\n",
    "plt.show()\n",
    "\n",
    "# Export the data to csv file\n",
    "measured_csv_data_lqr = np.array([Treal_lqr, np.asarray(Xreal_lqr).T[0], np.asarray(Xreal_lqr).T[1],Ureal_lqr]).T\n",
    "np.savetxt(\"es_measured_data_lqr.csv\", measured_csv_data_lqr, delimiter=',', header=\"time,pos,vel,tau\", comments=\"\")\n",
    "\n",
    "# Show the video\n",
    "from IPython.display import Video\n",
    "Video(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4c. ES+LQR Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = 5 # Final time (s)\n",
    "dt = 0.01 # Time step (s)\n",
    "Treal_es_lqr, Xreal_es_lqr, Ureal_es_lqr, Ureal_es_lqr_des, video_path = pendulum.run_on_hardware(tf, dt, controller=es_lqr_controller, user_token=user_token, preparation_time = 5.0) \n",
    "\n",
    "# Measured Position\n",
    "plt.figure\n",
    "plt.plot(Treal_es_lqr, np.asarray(Xreal_es_lqr).T[0])\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Position (rad)\")\n",
    "plt.title(\"Position (rad) vs Time (s)\")\n",
    "plt.show()\n",
    "\n",
    "# Measured Velocity\n",
    "plt.figure\n",
    "plt.plot(Treal_es_lqr, np.asarray(Xreal_es_lqr).T[1])\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Velocity (rad/s)\")\n",
    "plt.title(\"Velocity (rad/s) vs Time (s)\")\n",
    "plt.show()\n",
    "\n",
    "# Measured Torque\n",
    "plt.figure\n",
    "plt.plot(Treal_es_lqr, Ureal_es_lqr)\n",
    "plt.plot(Treal_es_lqr, Ureal_es_lqr_des)\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Torque (Nm)\")\n",
    "plt.title(\"Torque (Nm) vs Time (s)\")\n",
    "plt.show()\n",
    "\n",
    "# Export the data to csv file\n",
    "measured_csv_data_es_lqr = np.array([Treal_es_lqr, np.asarray(Xreal_es_lqr).T[0], np.asarray(Xreal_es_lqr).T[1],Ureal_es_lqr]).T\n",
    "np.savetxt(\"es_measured_data_es_lqr.csv\", measured_csv_data_es_lqr, delimiter=',', header=\"time,pos,vel,tau\", comments=\"\")\n",
    "\n",
    "# Show the video\n",
    "from IPython.display import Video\n",
    "Video(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "2e561352d58e4309a0532f8e67e26e14",
  "deepnote_persisted_session": {
   "createdAt": "2024-12-03T14:26:21.876Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
